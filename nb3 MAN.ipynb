{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"nb3.ipynb","provenance":[],"collapsed_sections":["jbjjgQTAn9Tp","uVCx_F4Wn9Tx","SRnm05Cdn9T1"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"jbjjgQTAn9Tp"},"source":["# METRIC-BASED META-LEARNING using Matching Networks"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTxkOW3In9Tq","executionInfo":{"status":"ok","timestamp":1617946029999,"user_tz":-330,"elapsed":22783,"user":{"displayName":"Shubham Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijAdgXGWwoUffD5VV0pixqu6iYKebE97tJptk0LQ=s64","userId":"14189324627242244147"}},"outputId":"cbb85504-6c46-467a-b342-f8b6798e3d3c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fV790yDVn9Tt","executionInfo":{"status":"ok","timestamp":1617946034635,"user_tz":-330,"elapsed":1042,"user":{"displayName":"Shubham Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijAdgXGWwoUffD5VV0pixqu6iYKebE97tJptk0LQ=s64","userId":"14189324627242244147"}},"outputId":"dfd2c545-0fad-4a37-eae9-8d1da09e32cd"},"source":["%cd drive/MyDrive/'Colab Notebooks/MetaLearning'\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/MetaLearning\n","l2lutils.ipynb\tmodels.ipynb  nb1.ipynb  nb2-CNP.ipynb\tnb3.ipynb  utils.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zgIKPO2In9Tu","executionInfo":{"status":"ok","timestamp":1617946078096,"user_tz":-330,"elapsed":39616,"user":{"displayName":"Shubham Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijAdgXGWwoUffD5VV0pixqu6iYKebE97tJptk0LQ=s64","userId":"14189324627242244147"}},"outputId":"d98a5473-0d90-44ff-d691-101b18af9c3c"},"source":["!pip install import_ipynb --quiet\n","!pip install learn2learn --quiet"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 1.4MB 6.0MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 37.1MB/s \n","\u001b[K     |████████████████████████████████| 174kB 33.1MB/s \n","\u001b[K     |████████████████████████████████| 102kB 7.9MB/s \n","\u001b[K     |████████████████████████████████| 61kB 5.5MB/s \n","\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n","\u001b[K     |████████████████████████████████| 1.4MB 36.0MB/s \n","\u001b[K     |████████████████████████████████| 112kB 52.7MB/s \n","\u001b[K     |████████████████████████████████| 3.2MB 44.1MB/s \n","\u001b[?25h  Building wheel for learn2learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for gsutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for gcs-oauth2-boto-plugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for retry-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyu2f (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"QhlXGQzsn9Tu","executionInfo":{"status":"ok","timestamp":1617946090991,"user_tz":-330,"elapsed":921,"user":{"displayName":"Shubham Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijAdgXGWwoUffD5VV0pixqu6iYKebE97tJptk0LQ=s64","userId":"14189324627242244147"}},"outputId":"a6a57b6b-0eb3-4bc4-ad69-881fc906151f"},"source":["import import_ipynb\n","import utils\n","import models\n","utils.hide_toggle('Imports 1')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","        <script>\n","            function code_toggle_8051676562369299053() {\n","                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n","            }\n","\n","            \n","        </script>\n","\n","        <a href=\"javascript:code_toggle_8051676562369299053()\"><b>Imports 1</b> (show/hide)</a>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"MEu4nB2Fn9Tv","executionInfo":{"status":"ok","timestamp":1617946094309,"user_tz":-330,"elapsed":960,"user":{"displayName":"Shubham Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijAdgXGWwoUffD5VV0pixqu6iYKebE97tJptk0LQ=s64","userId":"14189324627242244147"}},"outputId":"046a5914-46de-4316-cd42-defb6ba3d019"},"source":["from IPython import display\n","import torch\n","from sklearn.manifold import TSNE\n","from matplotlib import pyplot as plt\n","# from l2lutils import KShotLoader\n","from IPython import display\n","utils.hide_toggle('Imports 2')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","        <script>\n","            function code_toggle_1800347196682720003() {\n","                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n","            }\n","\n","            \n","        </script>\n","\n","        <a href=\"javascript:code_toggle_1800347196682720003()\"><b>Imports 2</b> (show/hide)</a>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"d_kySuvso9jj"},"source":["l2lutils"]},{"cell_type":"code","metadata":{"id":"LMfT2egdo99p"},"source":["import torch\n","import numpy as np\n","import learn2learn as l2l\n","from learn2learn.data import *\n","import import_ipynb\n","import utils\n","class KShotLoader():\n","    def __init__(self,myds,num_tasks=1000,shots=2,ways=2,classes=None):\n","        self.shots = shots\n","        self.ways = ways\n","        self.myMds = l2l.data.MetaDataset(myds)\n","        if classes == None:\n","            n_classes = len(set(myds.labels))\n","            classes = [i for i in range(n_classes)]\n","        self.my_tasks = l2l.data.TaskDataset(self.myMds, task_transforms=[\n","                                l2l.data.transforms.FilterLabels(self.myMds,classes),\n","                                l2l.data.transforms.NWays(self.myMds,ways),\n","                                l2l.data.transforms.KShots(self.myMds,2*shots),\n","                                l2l.data.transforms.LoadData(self.myMds),\n","                                l2l.data.transforms.RemapLabels(self.myMds),\n","                                l2l.data.transforms.ConsecutiveLabels(self.myMds)\n","                                ],num_tasks=num_tasks)\n","    def get_task(self):\n","        data,labels = self.my_tasks.sample()\n","        adaptation_indices = np.zeros(data.size(0), dtype=bool)\n","        adaptation_indices[np.arange(self.shots*self.ways) * 2] = True\n","        evaluation_indices = torch.from_numpy(~adaptation_indices)\n","        adaptation_indices = torch.from_numpy(adaptation_indices)\n","        adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n","        evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n","        d_train = (adaptation_data,adaptation_labels)\n","        d_test = (evaluation_data,evaluation_labels)\n","        return d_train, d_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uVCx_F4Wn9Tx"},"source":["# Data Generation and Loading"]},{"cell_type":"code","metadata":{"id":"7NVuuLgun9Ty"},"source":["#Generate data - euclidean\n","meta_train_ds, meta_test_ds, full_loader = utils.euclideanDataset(n_samples=10000,n_features=20,n_classes=10,batch_size=32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOW_ssJ4n9Tz"},"source":["# Define an MLP network. Note that input dimension has to be data dimension. For classification\n","# final dimension has to be number of classes; for regression one.\n","#torch.manual_seed(10)\n","net = models.MLP(dims=[20,32,32,10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qw7Q4pOan9Tz"},"source":["# Train the network; note that network is trained in place so repeated calls further train it.\n","net,loss,accs=models.Train(net,full_loader,lr=1e-2,epochs=50,verbose=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqXj2aFQn9T0"},"source":["#Training accuracy.\n","models.accuracy(net,meta_train_ds.samples,meta_train_ds.labels,verbose=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTXmJWRVn9T0"},"source":["# Test accuracy.\n","models.accuracy(net,meta_test_ds.samples,meta_test_ds.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SRnm05Cdn9T1"},"source":["# Meta-Learning: Tasks"]},{"cell_type":"markdown","metadata":{"id":"pfG2fHTkn9T1"},"source":["Generate a k-shot n-way loader using the meta-training dataset"]},{"cell_type":"code","metadata":{"id":"Vzm9xGTHn9T2"},"source":["meta_train_kloader=KShotLoader(meta_train_ds,shots=5,ways=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DMINw9zFn9T3"},"source":["Sample a task - each task has a k-shot n-way training set and a similar test set"]},{"cell_type":"code","metadata":{"id":"Kb1Q4TVkn9T3"},"source":["d_train,d_test=meta_train_kloader.get_task()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XLbtXr9ln9T3"},"source":["Let's try directly learning using the task training set albeit its small size: create a dataset and loader and train it with the earlier network and Train function."]},{"cell_type":"code","metadata":{"id":"cINHrFZcn9T4"},"source":["taskds = utils.MyDS(d_train[0],d_train[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ohrF7qtn9T5"},"source":["d_train_loader = torch.utils.data.DataLoader(dataset=taskds,batch_size=1,shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dHjtWXg8n9T5"},"source":["net,loss,accs=models.Train(net,d_train_loader,lr=1e-1,epochs=10,verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Byi0xY6pn9T6"},"source":["How does it do on the test set of the sampled task?"]},{"cell_type":"code","metadata":{"id":"E7y1ukavn9T7"},"source":["models.accuracy(net,d_test[0],d_test[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2xrZru1un9T7"},"source":["# Matching Networks"]},{"cell_type":"code","metadata":{"id":"QzC3DF2Mn9T_"},"source":["import learn2learn as l2l\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E2aqc4ytn9T_"},"source":["Sampling a training task: Note that each of d_train and d_test is a tuple comprising of a training set, and labels."]},{"cell_type":"code","metadata":{"id":"snl-n0q3n9UA"},"source":["d_train,d_test=meta_train_kloader.get_task()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y0OpFur5n9UA"},"source":["lossfn = torch.nn.NLLLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S4mwJy2dn9UA"},"source":["Cos computes cosine similarities between a batch of targets and a given support set"]},{"cell_type":"code","metadata":{"id":"fbTXMhFtn9UB"},"source":["class Cos(nn.Module):\n","    def __init__(self,dims=[20,32,32]):\n","        super(Cos,self).__init__()\n","    def forward(self,target,ss):\n","        # compute cosine distances between \n","        # target (batch,embedding_dim) and support set ss (ss_size,embedding_dim)\n","        # return (batch,ss_size)\n","        target_normed = F.normalize(target,p=2,dim=1)\n","        # shape of target_normed will be (batch,1,embedding_dim)\n","        ss_normed = F.normalize(ss,p=2,dim=1).permute(1,0)\n","        similarities = torch.mm(target_normed,ss_normed)\n","        # result will be (batch,ss_size)\n","        return similarities"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eru6KZrVn9UB"},"source":["Matching Network (simple - without Full-context embeddings)"]},{"cell_type":"code","metadata":{"id":"XpG6-G38n9UB"},"source":["class MAN(nn.Module):\n","    def __init__(self,dims=[20,32,32],n_classes=2,lr=1e-3):\n","        super(MAN,self).__init__()\n","        self.n_classes = n_classes\n","        self.mlp = models.MLP(dims=dims,task='embedding')\n","        self.cos = Cos()\n","        self.attn = nn.Softmax(dim=1)\n","        self.optimizer = optim.Adam(self.parameters(),lr=lr)\n","    def forward(self,X,d_train):\n","        # X = (batch,n_features)\n","        (x_tr,y_tr) = d_train\n","        # x_tr = (ss_size,n_features), y_tr = (ss_size)\n","        ss_e = self.mlp(x_tr)\n","        X_e = self.mlp(X)\n","        sims = self.cos(X_e,ss_e)\n","        # size (batch,ss_size)\n","        attn_wts = self.attn(sims)\n","        y_h = torch.eye(self.n_classes)[y_tr]\n","        # y_h = one-hot version of y_tr = (ss_size,n_classes)\n","        preds = attn_wts@y_h\n","        return preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KmPA2MyFn9UC"},"source":["X = torch.Tensor([[1,1,1],[-1,-1,-1],[1,2,3],[-1,-2,-3]])\n","y_tr = torch.LongTensor([0,1])\n","x_tr = X[[0,1],:]\n","d_tr = (x_tr,y_tr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EIKKhHV0n9UC"},"source":["man = MAN(dims=[3,8,8])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWn25iyNn9UC","executionInfo":{"status":"ok","timestamp":1617948134140,"user_tz":-330,"elapsed":1171,"user":{"displayName":"Shubham Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijAdgXGWwoUffD5VV0pixqu6iYKebE97tJptk0LQ=s64","userId":"14189324627242244147"}},"outputId":"ea2735ca-1451-4511-a2d5-e6ca5f251748"},"source":["man(X,d_tr)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.5584, 0.4416],\n","        [0.4416, 0.5584],\n","        [0.5633, 0.4367],\n","        [0.4027, 0.5973]], grad_fn=<MmBackward>)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"BDLq7liPn9UC"},"source":["# Putting it all together: Training a Matching Network\n","Now let's put all of the above in a loop - training Matching Network algorithm:"]},{"cell_type":"code","metadata":{"id":"TqDqEA8Xn9UD"},"source":["# Redefining accuracy function so that it takes h - dataset context - as input since net requires it.\n","def accuracy(Net,X_test,y_test,h,verbose=True):\n","    #Net.eval()\n","    m = X_test.shape[0]\n","    y_pred = Net(X_test,h)\n","    _, predicted = torch.max(y_pred, 1)\n","    correct = (predicted == y_test).float().sum().item()\n","    if verbose: print(correct,m)\n","    accuracy = correct/m\n","    #Net.train()\n","    return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iz2r00Ldn9UD","executionInfo":{"status":"ok","timestamp":1617948238373,"user_tz":-330,"elapsed":1194,"user":{"displayName":"Shubham Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijAdgXGWwoUffD5VV0pixqu6iYKebE97tJptk0LQ=s64","userId":"14189324627242244147"}},"outputId":"06ccec09-5c85-41ea-f79d-f5fd62d98f07"},"source":["classes_train = [i for i in range(5)]\n","classes_test = [i+5 for i in range(5)]\n","classes_train, classes_test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0, 1, 2, 3, 4], [5, 6, 7, 8, 9])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"EHwIrTqrn9UE"},"source":["import learn2learn as l2l\n","import torch.optim as optim\n","shots,ways = 5,5\n","net = MAN(n_classes=ways,dims=[20,64,32],lr=1e-4)\n","lossfn = torch.nn.NLLLoss()\n","meta_train_kloader=KShotLoader(meta_train_ds,shots=shots,ways=ways,num_tasks=1000,classes=classes_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1Rnq1t2n9UE","executionInfo":{"status":"ok","timestamp":1617948373931,"user_tz":-330,"elapsed":37686,"user":{"displayName":"Shubham Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijAdgXGWwoUffD5VV0pixqu6iYKebE97tJptk0LQ=s64","userId":"14189324627242244147"}},"outputId":"d8a9b275-8c1c-4299-c341-709d89e7c7d9"},"source":["epoch=0\n","n_epochs=100\n","task_count=50\n","while epoch<n_epochs:\n","    test_loss = 0.0\n","    test_acc = 0.0\n","    # Sample and train on a task\n","    for task in range(task_count):\n","        d_train,d_test=meta_train_kloader.get_task()\n","        rp = torch.randperm(d_train[1].shape[0])\n","        d_train0=d_train[0][rp]\n","        d_train1=d_train[1][rp]\n","        x_tr = d_train0\n","        d_tr = x_tr \n","        rp1 = torch.randperm(d_test[1].shape[0])\n","        d_test0=d_test[0][rp1]\n","        d_test1=d_test[1][rp1]\n","        x_ts = d_test0\n","        d_ts = x_ts \n","        test_preds = net(d_ts,(x_tr,d_train1))\n","        #train_preds = net(d_tr,h)\n","        # Accumulate losses over tasks - note train and test loss both included\n","        test_loss += lossfn(test_preds,d_test1)\n","        net.eval()\n","        test_acc += accuracy(net,d_ts,d_test1,(x_tr,d_train1),verbose=False)\n","        net.train()\n","    #Update the network weights\n","    print('Epoch  % 2d Loss: %2.5e Avg Acc: %2.5f'%(epoch,test_loss/task_count,test_acc/task_count))\n","    display.clear_output(wait=True)\n","    net.optimizer.zero_grad()\n","    test_loss.backward()\n","    net.optimizer.step()\n","    epoch+=1\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch   99 Loss: -2.75586e-01 Avg Acc: 0.77280\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fD3Valr9n9UF"},"source":["Now test the trained matching network and to tasks sampled from the meta_test_ds dataset:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_5OOdxXn9UF","executionInfo":{"status":"ok","timestamp":1617948380094,"user_tz":-330,"elapsed":1260,"user":{"displayName":"Shubham Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijAdgXGWwoUffD5VV0pixqu6iYKebE97tJptk0LQ=s64","userId":"14189324627242244147"}},"outputId":"5ecbac17-7076-44e1-d50c-34461a99fd05"},"source":["meta_test_kloader=KShotLoader(meta_test_ds,shots=shots,ways=ways,classes=classes_test)\n","test_acc = 0.0\n","task_count = 50\n","adapt_steps = 1\n","# Sample and train on a task\n","for task in range(task_count):\n","    d_train,d_test=meta_test_kloader.get_task()\n","    x_tr = d_train[0]\n","    y_tr_sh = torch.cat((torch.zeros(1,ways),torch.eye(ways)[d_train[1][1:]]))\n","    d_tr = x_tr #torch.cat((x_tr,y_tr_sh),1)\n","    x_ts = d_test[0]\n","    y_ts_sh = torch.zeros(x_ts.shape[0],ways)\n","    d_ts = x_ts #torch.cat((x_ts,y_ts_sh),1)\n","    test_preds = net(d_ts,(d_tr,d_train[1]))\n","    test_acc += accuracy(net,d_ts,d_test[1],(d_tr,d_train[1]),verbose=False)\n","    # Done with a task\n","net.train()\n","print('Avg Acc: %2.5f'%(test_acc/task_count))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Avg Acc: 0.68960\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s1aBgZTan9UF"},"source":[""],"execution_count":null,"outputs":[]}]}